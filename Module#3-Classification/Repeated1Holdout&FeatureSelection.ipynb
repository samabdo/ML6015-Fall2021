{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8f8e78",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "1. This lecture is to give the students hands-on activities on repeated 1-holdout cross-validation with the introduction to feature selection.\n",
    "2. You want to study the below medium links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24a3ac",
   "metadata": {},
   "source": [
    "# Define a problem statement and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c64f1",
   "metadata": {},
   "source": [
    "# [Understand the dataset and features](https://archive.ics.uci.edu/ml/datasets/hepatitis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b818384",
   "metadata": {},
   "source": [
    "## Features\n",
    "   \n",
    "     1. Class: DIE, LIVE\n",
    "     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\n",
    "     3. SEX: male, female\n",
    "     4. STEROID: no, yes\n",
    "     5. ANTIVIRALS: no, yes\n",
    "     6. FATIGUE: no, yes\n",
    "     7. MALAISE: no, yes\n",
    "     8. ANOREXIA: no, yes\n",
    "     9. LIVER BIG: no, yes\n",
    "    10. LIVER FIRM: no, yes\n",
    "    11. SPLEEN PALPABLE: no, yes\n",
    "    12. SPIDERS: no, yes\n",
    "    13. ASCITES: no, yes\n",
    "    14. VARICES: no, yes\n",
    "    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\n",
    "    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\n",
    "    17. SGOT: 13, 100, 200, 300, 400, 500, \n",
    "    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\n",
    "    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\n",
    "    20. HISTOLOGY: no, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0278f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import loguniform\n",
    "from statistics import mean\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#class sklearn.model_selection.StratifiedShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
    "\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,StackingClassifier,VotingClassifier\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce916866",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/DATA/hepatitis.csv', thousands=',', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f28982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above there is no datatype object that condradicts with the above description\n",
    "allFeatures=data.columns[1:len(data.columns)]\n",
    "catFeatures=data.columns[list(range(2,14))+list(range(15,17))+list(range(18,20))]\n",
    "numFeatures= [i for i in allFeatures if not(i in catFeatures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9977d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "catFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in-place command \n",
    "for c in catFeatures:\n",
    "    data[c]=data[c].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58214351",
   "metadata": {},
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numFeatures].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d907f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numFeatures].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "\n",
    "\n",
    "for cat in catFeatures:\n",
    "    fig, ax = plt.subplots()\n",
    "    data[cat].value_counts().plot(ax=ax, kind='bar', xlabel=cat, ylabel='frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalance dataset\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce4c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[1:20]]\n",
    "y = data[data.columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e04692",
   "metadata": {},
   "source": [
    "# Developing Imputer and Standardized Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "scalor=StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62379c15",
   "metadata": {},
   "source": [
    "# Developing baseline and ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineClassifiers=[LogisticRegression(), SVC(), KNeighborsClassifier()] #DecisionTreeClassifier()\n",
    "nameBaselineClassifiers=['LR','SVC','KNN'] #'DT'\n",
    "\n",
    "estimators=[]\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    estimators.append((nameBaselineClassifiers[bc],baselineClassifiers[bc]))\n",
    "\n",
    "vote_hard_clf = VotingClassifier(estimators = estimators, voting ='hard')\n",
    "rf_clf=RandomForestClassifier(max_depth=7, random_state=0)\n",
    "\n",
    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=rf_clf)\n",
    "ada_clf=AdaBoostClassifier(base_estimator=rf_clf,n_estimators=200, random_state=0)\n",
    "bagging_cls=BaggingClassifier(base_estimator=rf_clf,n_estimators=200,max_samples=0.5, max_features=0.5)\n",
    "gb_clf= GradientBoostingClassifier(n_estimators=100, learning_rate=0.02, max_depth=3, random_state=0)\n",
    "\n",
    "ensemble_classifiers=[vote_hard_clf,rf_clf,stack_clf,ada_clf,bagging_cls,gb_clf]\n",
    "nameEnsembleClassifiers=['voting','RandomForest','stacking','AdaBoost','Bagging','GB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6f947",
   "metadata": {},
   "source": [
    "# Splitting the data: Use any Splitting Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_splits=5\n",
    "sss = StratifiedShuffleSplit(n_splits=number_of_splits, test_size=0.3, random_state=0)\n",
    "train_indexes=[]\n",
    "test_indexes=[]\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    train_indexes.append(train_index)\n",
    "    test_indexes.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[numFeatures])\n",
    "        X_train[numFeatures]=scalor.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=scalor.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29197c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ec in range(0,len(ensemble_classifiers)):\n",
    "    print(nameEnsembleClassifiers[ec])\n",
    "    results[nameEnsembleClassifiers[ec]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[numFeatures])\n",
    "        X_train[numFeatures]=scalor.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=scalor.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        model=ensemble_classifiers[ec].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameEnsembleClassifiers[ec]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameEnsembleClassifiers[ec]]))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad736e1",
   "metadata": {},
   "source": [
    "# Which classifier is the best based on the mean of repeated 1 holdout cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=''\n",
    "maximum=float('-inf')\n",
    "for nameClassifier in results.keys():\n",
    "    avg=np.average(results[nameClassifier])\n",
    "    if (avg > maximum):\n",
    "        maximum=avg\n",
    "        maxClassifier=nameClassifier\n",
    "\n",
    "print('The classifier {0} is the minumm average of {1}'.format(maxClassifier,maximum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a378d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_significance=[]\n",
    "for nameClassifier in results.keys():\n",
    "    test_significance.append(results[nameClassifier])\n",
    "\n",
    "#Check if Friedman test is signifiant\n",
    "chi_square,p_value_mean=stats.friedmanchisquare(*test_significance)\n",
    "print(p_value_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_groups=np.array(test_significance).T\n",
    "p=posthoc_nemenyi_friedman(trans_groups)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9f2af",
   "metadata": {},
   "source": [
    "# Feature selection methods \n",
    "\n",
    "\n",
    "What is the differences between feature selection methods, dimensionality reduction, and feature extraction?\n",
    "\n",
    "\n",
    "\n",
    "Resources are [link1](https://towardsdatascience.com/feature-selection-for-machine-learning-3-categories-and-12-methods-6a4403f86543) and [link2](https://towardsdatascience.com/feature-selection-for-machine-learning-3-categories-and-12-methods-6a4403f86543) \n",
    "\n",
    "In [Sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89788ef4",
   "metadata": {},
   "source": [
    "## Feature selection \n",
    "\n",
    "1. It eliminates irrelevant and noisy features by keeping the ones with minimum redundancy and maximum relevance to the target variable.\n",
    "2. It reduces the computational time and complexity of training and testing a classifier, so it results in more cost-effective models.\n",
    "3. It improves learning algorithms’ performance, avoids overfitting, and helps to create better general models.\n",
    "\n",
    "There are three categories of feature selection methods, depending on how they interact with the classifier, namely: \n",
    "1. filter.\n",
    "2. wrapper.\n",
    "3. embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb05460",
   "metadata": {},
   "source": [
    "### Filter methods \n",
    "\n",
    "They are scalable (up to very high-dimensional data) and perform fast feature selection before classification so that the bias of a learning algorithm does not interact with the bias of the feature selection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394086dd",
   "metadata": {},
   "source": [
    "#### Chi-square\n",
    "\n",
    "If the target variable is independent of the feature, then it gets a low score, or if they are dependent, the feature is important. A higher value of chi-square means that the feature is more relevant concerning the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "chi_selector = SelectKBest(chi2, k=15)  #Use k='all' if you need to rank all \n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        cols=X_train.columns\n",
    "    \n",
    "        #Feature Selection\n",
    "        chi_selector.fit(X_train,y_train)\n",
    "        X_train=chi_selector.transform(X_train)\n",
    "        X_test=chi_selector.transform(X_test)\n",
    "        \n",
    "        column_names = cols[chi_selector.get_support()]\n",
    "        \n",
    "        X_train=pd.DataFrame(X_train,columns=column_names)\n",
    "        X_test=pd.DataFrame(X_test,columns=column_names)    \n",
    "        newNumFeaturs=[num for num in numFeatures if num in column_names]\n",
    "        newCatFeaturs=[num for num in catFeatures if num in column_names]\n",
    "            \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[newNumFeaturs])\n",
    "        X_train[newNumFeaturs]=scalor.transform(X_train[newNumFeaturs])\n",
    "        X_test[newNumFeaturs]=scalor.transform(X_test[newNumFeaturs])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train,columns=newCatFeaturs)\n",
    "        X_test=pd.get_dummies(X_test,columns=newCatFeaturs)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb6fc4",
   "metadata": {},
   "source": [
    "####  Mutual Information\n",
    "\n",
    "A feature is considered relevant if it has a high information gain. It cannot handle redundant features, because features are selected in a univariate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "me_selector = SelectKBest(mutual_info_classif, k=15)  #Use k='all' if you need to rank all \n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        cols=X_train.columns\n",
    "    \n",
    "        #Feature Selection\n",
    "        me_selector.fit(X_train,y_train)\n",
    "        X_train=me_selector.transform(X_train)\n",
    "        X_test=me_selector.transform(X_test)\n",
    "        \n",
    "        column_names = cols[me_selector.get_support()]\n",
    "        \n",
    "        X_train=pd.DataFrame(X_train,columns=column_names)\n",
    "        X_test=pd.DataFrame(X_test,columns=column_names)    \n",
    "        newNumFeaturs=[num for num in numFeatures if num in column_names]\n",
    "        newCatFeaturs=[num for num in catFeatures if num in column_names]\n",
    "            \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[newNumFeaturs])\n",
    "        X_train[newNumFeaturs]=scalor.transform(X_train[newNumFeaturs])\n",
    "        X_test[newNumFeaturs]=scalor.transform(X_test[newNumFeaturs])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train,columns=newCatFeaturs)\n",
    "        X_test=pd.get_dummies(X_test,columns=newCatFeaturs)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1e63c",
   "metadata": {},
   "source": [
    "####  Wrapper methods\n",
    "\n",
    "This widely used wrapper method uses an algorithm to train the model iteratively and each time removes the least important feature using the weights of the algorithm as the criterion.\n",
    "It is a multivariate method in the sense that it evaluates the relevance of several features considered jointly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48ea8a",
   "metadata": {},
   "source": [
    "## Using from scipy.stats feature selection\n",
    "\n",
    "1. [Mann–Whitney U test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)\n",
    "2. [Chi-Squared test](https://en.wikipedia.org/wiki/Chi-squared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu,chi2_contingency,chi2\n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        \n",
    "        newCatFeatures=[]\n",
    "        for fe in catFeatures:\n",
    "            table=pd.crosstab(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            _, p, _, _ = chi2_contingency(table)\n",
    "            if (p <=0.05):\n",
    "                 newCatFeatures.append(fe) \n",
    "        \n",
    "        \n",
    "        newNumFeatures=[]\n",
    "        for fe in numFeatures:\n",
    "            _, p = mannwhitneyu(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            if (p <=0.05):\n",
    "                newNumFeatures.append(fe)\n",
    "    \n",
    "        #print('Feature Selection')\n",
    "        #print(numFeatures)\n",
    "        #print(catFeatures)\n",
    "        #print(newNumFeatures)\n",
    "        #print(newCatFeatures)\n",
    "        #input('Feature Selection')\n",
    "        \n",
    "        catFeatures=newCatFeatures\n",
    "        numFeatures=newNumFeatures\n",
    "        X_train=X_train[numFeatures+newCatFeatures]\n",
    "        X_test=X_test[numFeatures+newCatFeatures]\n",
    "        \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[numFeatures])\n",
    "        X_train[numFeatures]=scalor.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=scalor.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fdb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ec in range(0,len(ensemble_classifiers)):\n",
    "    print(nameEnsembleClassifiers[ec])\n",
    "    results[nameEnsembleClassifiers[ec]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "    \n",
    "    \n",
    "        newCatFeatures=[]\n",
    "        for fe in catFeatures:\n",
    "            table=pd.crosstab(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            _, p, _, _ = chi2_contingency(table)\n",
    "            if (p <=0.05):\n",
    "                 newCatFeatures.append(fe) \n",
    "        \n",
    "        \n",
    "        newNumFeatures=[]\n",
    "        for fe in numFeatures:\n",
    "            _, p = mannwhitneyu(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            if (p <=0.05):\n",
    "                newNumFeatures.append(fe)\n",
    "    \n",
    "        #print('Feature Selection')\n",
    "        #print(numFeatures)\n",
    "        #print(catFeatures)\n",
    "        #print(newNumFeatures)\n",
    "        #print(newCatFeatures)\n",
    "        #input('Feature Selection')\n",
    "        \n",
    "        catFeatures=newCatFeatures\n",
    "        numFeatures=newNumFeatures\n",
    "        X_train=X_train[numFeatures+newCatFeatures]\n",
    "        X_test=X_test[numFeatures+newCatFeatures]\n",
    "    \n",
    "        #Scaling numeric features\n",
    "        scalor.fit(X_train[numFeatures])\n",
    "        X_train[numFeatures]=scalor.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=scalor.transform(X_test[numFeatures])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "                \n",
    "        \n",
    "        \n",
    "        model=ensemble_classifiers[ec].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameEnsembleClassifiers[ec]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameEnsembleClassifiers[ec]]))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a881b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
